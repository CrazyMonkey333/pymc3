{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\"> \n",
    "# Lesson: PyMC & Bayesian Regression\n",
    "\n",
    "_Authors: Tim Book, Matt Brems, Noelle Brown_\n",
    "\n",
    "## LEARNING OBJECTIVES\n",
    "By the end of the lesson, students should be able to:\n",
    "- Define conjugacy.\n",
    "- Fit models in PyMC.\n",
    "- Interpret traceplots, posterior distributions, and posterior predictions.\n",
    "\n",
    "---\n",
    "\n",
    "## Recap\n",
    "Remember that parameters have distributions. In Bayesian statistics, our goal is to **find the posterior distribution of our parameter of interest**.\n",
    "\n",
    "<details><summary>In order to generate a posterior distribution, what are the two components we need?</summary>\n",
    "\n",
    "- Prior distribution summarizing our beliefs about the parameter before observing any data.\n",
    "- Likelihood function summarizing how our data were generated.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Bayes?\n",
    "There are several reasons why we would prefer to use a Bayesian technique over a frequentist one. What are they? (THREAD)\n",
    "\n",
    "<details>\n",
    "    <summary>What are some reasons to use Bayesian techniques?</summary>\n",
    "    \n",
    "* When you have prior knowledge of a situation (ie, you might no better than data suggests)\n",
    "* When you have small data that can benefit from additional subject matter expertise\n",
    "* When you want to be able to make advanced probabilistic statements that are unavailable to frequentist techniques\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chain Monte Carlo Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monte Carlo simulations are used to model much more complicated things as well. In calculus, if you remember calculating the integral (area under the curve), you had to remember those nasty \"integration by parts\" formulas and \"u-substitution.\" Monte Carlo simulations make that [relatively trivial with computers](https://www.youtube.com/watch?v=GZXhGwCXct0)!\n",
    "\n",
    "You may remember that we discussed Monte Carlo simulations all the way back in the Introduction to Probability lesson. Some of the problems in the notebook included \"Suppose you roll three dice. What is the probability that the three dice are rolled in increasing order?\" and \"I flip my coin until I flip heads. I count up the number of coins I flipped and roll that many dice. What is the probability that the average roll will be between 3 and 4 (inclusive)?\"\n",
    "- These might be good probability problems to practice!\n",
    "\n",
    "Monte Carlo simulations aren't inherently Bayesian by themselves. But the way that `PyMC3` and most programs will find the posterior distribution of the parameter of interest will be to use Markov Chain Monte Carlo methods, or MCMC methods.\n",
    "\n",
    "## Primer on Markov Chain Monte Carlo Methods\n",
    "\n",
    "Here's a quick, three-minute run-down of Markov Chain Monte Carlo methods.\n",
    "\n",
    "There are three main components to MCMC Methods.\n",
    "- Monte Carlo Methods\n",
    "- Markov Chains\n",
    "- Acceptance-Rejection Sampling\n",
    "\n",
    "If we were to just generate random numbers without any rhyme or reason, we'd be doing basic Monte Carlo simulations.\n",
    "<img src=\"./images/montecarlo.gif\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "Suppose that, instead, we're still generating random numbers. However, this time, the last random number we generate influences the next random number we generate. This incorporates Markov chains.\n",
    "<img src=\"./images/markovchain.gif\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "The final component, \"acceptance-rejection sampling,\" will take each random sample and accept it or reject it, based on how \"good\" it is. The algorithm for doing this uses the prior and likelihood that you came up with to determine if this sample is \"good enough.\" The basic algorithm is called the [Metropolis-Hastings Algorithm](https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm).\n",
    "\n",
    "<img src=\"./images/acceptancerejection.gif\" alt=\"drawing\" width=\"550\"/>\n",
    "\n",
    "All of this will happen when you run `pymc3.sample()` below!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Acceptance-Rejection Sampling\n",
    "\n",
    "- Acceptance-rejection sampling is a specific type of Monte Carlo sampling.\n",
    "\n",
    "- We’re going to sample some observation, then decide whether to keep it (accept it) or discard it (reject it). \n",
    "    - Specifically, we will accept these values a certain percentage of the time and reject a certain percentage of the time.\n",
    "\n",
    "- As our random walk moves about, we need some way to make sure that we’re moving in the right direction.\n",
    "    - If we are moving in the right direction, we’ll accept that sample.\n",
    "    - If we aren’t moving in the right direction, we may reject that sample.\n",
    "\n",
    "We’ll walk through a specific algorithm to accept/reject, called the [Metropolis-Hastings algorithm](https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm).\n",
    "- PyMC by default will implement a more sophisticated algorithm called the [No U-Turn Sampler](https://arxiv.org/abs/1111.4246).\n",
    "\n",
    "The Metropolis-Hastings algorithm allows us to, at each step, identify whether we are getting “hotter” or “colder.”\n",
    "\n",
    "#### Metropolis-Hastings Algorithm\n",
    "Part 1. Generate $\\theta_{proposal} \\sim N(\\theta_{t-1}, \\sigma)$.\n",
    "\n",
    "Part 2. Calculate the ratio of posterior probabilities $r = \\frac{P(\\theta_{proposal}|y)}{P(\\theta_{t-1}|y)}$.\n",
    "- Since we have specified the prior and the likelihood, we can just find the posterior probability of these specific values!\n",
    "- If $r \\ge 1$, then $\\theta_{proposal}$ is a likelier value for our posterior distribution than $\\theta_{t-1}$. You can think of this as \"we're heading in the right direction.\"\n",
    "- If $r < 1$, then $\\theta_{proposal}$ is not a likelier value for our posterior distribution than $\\theta_{t-1}$. You can think of this as \"we're heading in a direction of lower probability.\"\n",
    "\n",
    "Part 3. Calculate our acceptance probability $\\alpha = \\min\\{r,1\\}$.\n",
    "- This is the probability that we'll accept $\\theta_{proposal}$ as our new value $\\theta_t$.\n",
    "- If $r \\ge 1$, then $\\theta_{proposal}$ is a likelier value for our posterior distribution than $\\theta_{t-1}$ and our acceptance probability is 100%!\n",
    "- If $r < 1$, then $\\theta_{proposal}$ is not a likelier value for our posterior distribution than $\\theta_{t-1}$, so we may reject $\\theta_{proposal}$.\n",
    "\n",
    "Part 4. We want to get our computer to basically flip a coin with probability of success $\\alpha$ to determine whether or not we accept $\\theta_{proposal}$. We generate $U_t \\sim Uniform(0,1)$.\n",
    "- If $U_t \\le \\alpha$, then accept $\\theta_{proposal}$. (That is, $\\theta_t = \\theta_{proposal}$.)\n",
    "- If $U_t > \\alpha$, then reject $\\theta_{proposal}$. (That is, $\\theta_t = \\theta_{t-1}$.)\n",
    "\n",
    "Remember that we've already seen how Markov chains and Monte Carlo simulations can work together. Let's add the acceptance/rejection component to this!\n",
    "\n",
    "\n",
    "We will repeat this process a large number of times - the number of samples we generate with `pm.sample()`.\n",
    "\n",
    "Once we do this long enough and visually inspect traceplots to convince ourselves that we have “converged” to the posterior distribution of interest, we usually discard early samples (before we converged), then we store some large $n$ of the later samples.\n",
    "- We might run this multiple times (by setting `chains` > 1 in `PyMC`) to protect against converging to a local optimum.\n",
    "\n",
    "Once we have our sample of size $n$, we can conduct whatever inference we want on the posterior distribution of the parameter of interest.\n",
    "- Find the mean.\n",
    "- Find the median.\n",
    "- Find the 95% ‘highest posterior density.’\n",
    "- Find the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install pymc3\n",
    "# !pip install pymc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages:\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pymc3 as pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Skittles!\n",
    "In a snack-size pack of Skittles, you are concerned with getting an unfair amount of green Skittles (the worst flavor). You think there are about 20 skittles per pack. There are 5 different colors of Skittles. \n",
    "\n",
    "<img src=\"./images/skittles.jpeg\" style=\"height: 300px\"> \n",
    "\n",
    "How can we determine if we get an unfair amount of green Skittles?\n",
    "\n",
    "**A frequentist would...**\n",
    "- Open many snack-size packs of Skittles, and estimate $\\hat{p}$, the probability of getting a green skittle.\n",
    "- Conduct a hypothesis test to determine if $p = 0.2$.\n",
    "\n",
    "**A Bayesian would...**\n",
    "- Begin with a preconceived notion about $p$ (a prior). This prior reflects not just our belief, but the strength of our belief.\n",
    "- Open many snack-size packs of Skittles and record the results (the likelihood).\n",
    "- Obtain a posterior distribution for $p$ that combines our priors with our data.\n",
    "- Make statements about this posterior.\n",
    "\n",
    "What is the (posterior) distribution of the number of green skittles I might find in a pack?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import green skittle count data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define our likelihood and priors\n",
    "\n",
    "We'll start with our priors. \n",
    "\n",
    "What do we know/believe about the percentage of green skittles we might find in a pack? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What distribution will be best for this?</summary>\n",
    "\n",
    "- The percentage of green skittles we might find in a pack is a number between 0 and 1.\n",
    "- The Beta distribution will be good here!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Beta Distribution\n",
    "Recall that the beta distribution is a **continuous** distribution. It's often used in Bayesian statistics because it's one of the only continuous distributions that take values between 0 and 1. This makes it particularly convenient to use as a prior on probabilities.\n",
    "\n",
    "You can take a closer look at the Beta distribution [here](https://en.wikipedia.org/wiki/Beta_distribution)!\n",
    "\n",
    "If $X \\sim \\text{Beta}(a, b)$, then\n",
    "\n",
    "* $\\text{E}[X] = \\frac{a}{a + b}$\n",
    "* $\\text{Var}[X] = \\frac{ab}{(a + b)^2(a + b + 1)}$\n",
    "\n",
    "Also note: The $\\text{Beta}(1, 1)$ distribution is actually the $\\text{Uniform}(0, 1)$ distrubtion!\n",
    "\n",
    "Let's compute some beta means and variances. What do you think is a reasonable prior for our problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>In my opinion, setting up your priors and likelihoods is the hardest part of Bayesian inference.</summary>\n",
    "\n",
    "![](./images/modified_bayes.png)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta_stats(a, b):\n",
    "    mean_ = a / (a + b)\n",
    "    var_ = a*b / ((a + b)**2 * (a + b + 1))\n",
    "    return mean_, var_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We want the mean to be about 0.2 (20% of each flavor)\n",
    "beta_stats( , )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior for percentage of green skittles we might find in a pack\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>We can also set a prior on the number of Skittles that are in a pack! What distribution will be best for this?</summary>\n",
    "\n",
    "- The number of Skittles in each pack is count data.\n",
    "- The Poisson distribution will work well here!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior for number of Skittles in a pack\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define our likelihood. \n",
    "\n",
    "We are interested in seeing how many green Skittles are in a bag.\n",
    "\n",
    "There's a fixed number of Skittles in a bag. Each of those Skittles has some probability of being green or not green.\n",
    "We are looking to see if a Skittle is green or not in our bag. \n",
    "\n",
    "A good tip from [Bayesian Methods for Hackers:](https://nbviewer.jupyter.org/github/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/blob/master/Chapter2_MorePyMC/Ch2_MorePyMC_PyMC3.ipynb)  \n",
    "> \"A good starting thought to Bayesian modeling is to think about how your data might have been generated. Position yourself in an omniscient position, and try to imagine how you would recreate the dataset.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What distribution will be best for this?</summary>\n",
    "\n",
    "- Each Skittle has some probability of being green and some probability of being not green.\n",
    "- The Binomial distribution will work here.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Likelihood\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCMC Using PyMC3\n",
    "Markov chain Monte Carlo methods (commonly abbreviated MCMC methods) made conjugacy mostly unnecessary.\n",
    "\n",
    "![](./images/pymc3-res.png)\n",
    "\n",
    "[TL;DR](https://en.wikipedia.org/wiki/TL;DR) of MCMC: We use computers to take our prior and likelihood, then simulate a large number of samples from the posterior.\n",
    "- If I want to find the mean of my posterior distribution, then I can just do `np.mean(xs)`, where `xs` is my saved list of samples from my posterior.\n",
    "- If I want to find the median of my posterior distribution, then I can do `np.median(xs)`.\n",
    "- If I want to find the 95% [credible interval](http://www.statisticshowto.com/credible-interval/) for my parameter based on the posterior distribution of my parameter, then I can just find the 2.5th and 97.5th percentiles of `xs`!\n",
    "\n",
    "Today, we're going to use `PyMC3`, a Bayesian modeling library in Python that will enable us to use Markov chain Monte Carlo methods. Luckily, this is a package that is geared toward scientists, not necessarily statisticians. We'll be able to use what we currently know about Bayesian statistics to leverage this *really* powerful library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Situation:\n",
    "$$\n",
    "\\begin{align}\n",
    "    X | p &\\sim \\text{Binomial}(n, p) \\\\\n",
    "        p &\\sim \\text{Beta}(a, b)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We've also observed a certain number of greens in our 20 bags (our data).\n",
    "\n",
    "### PyMC3 models live in \"contexts\" instead of \"objects\"\n",
    "That means they'll look something like this:\n",
    "\n",
    "```python\n",
    "with pm.Model() as model:\n",
    "    # Define priors\n",
    "    # Define likelihood\n",
    "    # Execute MCMC\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Let's set this up in PyMC3!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use PyMC3 to solve for the posterior distribution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected mean that an individual skittle will be grean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected amount of green skittles is number of skittles in bag * prob of green\n",
    "mean_green = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the probability we will get an expected value of between 5 and 6 green skittles?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Election Day\n",
    "\n",
    "Let's review the election example from the other day using polling data from [FiveThirtyEight](https://projects.fivethirtyeight.com/2020-election-forecast/). This time, we will look at the probability that Trump wins.\n",
    "\n",
    "Reminder: our polls gave us the following totals:\n",
    "\n",
    "```python\n",
    "n_biden = 7_616 # number of successes\n",
    "n_surveys = 14_995 # number of trials\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are the results of our polls.\n",
    "# 1 = Trump led the poll\n",
    "# 0 = Biden led the poll\n",
    "polls = np.array([1]*7379 + [0]*7616)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Establish our priors and our likelihood\n",
    "\n",
    "Here we are looking for the percentage of votes Trump is likely to win in the election.\n",
    "\n",
    "An important thing to note is that there is no such thing as sample data for problems like this, since elections only ever happen once. This is why pollsters conduct polls - to gather information about what will _probably_ happen in the future. Polls aren't perfect though, and they also change over time. **We know through personal experience that most elections end up being very close to 50/50.**\n",
    "\n",
    "We can use the Beta distribution for our prior. We need a mean of .5 (because we expect the election to be 50/50).\n",
    "\n",
    "_Hint:_ The priors are as subjective as they can get here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Likelihood\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Set up the PyMC3 model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyMC3 model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traceplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Expected value that Trump will get more than 50% of the votes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that we didn't take any outside factors into account (which FiveThirtyEight does) or even talk about the electoral college. Read more about FiveThirtyEight's modeling [here](https://fivethirtyeight.com/features/how-fivethirtyeights-2020-presidential-forecast-works-and-whats-different-because-of-covid-19/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Bayesian Regression for Pay Equity\n",
    "It is an often-recited statistic that women are paid about 77 cents per dollar a man makes for equal work. But how is this number (and others like it) calculated? We actually conduct a log-regression based on a person's legitimate skill level (ie, things such as education or years of experience that may legitimately contribute to you being paid more) and an indicator for the protected class. For example:\n",
    "\n",
    "$$ \\log W = \\beta_0 + \\beta_1\\text{skill} + \\beta_2\\text{class} $$\n",
    "\n",
    "After exponentiating both sides:\n",
    "\n",
    "$$ W = e^{\\beta_0 + \\beta_1\\text{skill}}e^{\\beta_2\\text{class}} $$\n",
    "\n",
    "Where $e^{\\beta_2\\text{class}}$ simplifies to:\n",
    "\n",
    "* $e^{\\beta_2}$ if you are the (potentially) discriminated class.\n",
    "* $e^0 = 1$ if you are not the (potentially) discriminated class.\n",
    "\n",
    "Thus, given a dataset of salaries at a company, we might seek to estimate $e^{\\beta_2\\text{class}}$ to prove/disprove pay equity discrimination. Using the power of Bayesian statistics, we can actually begin with a prior assumption of _no_ pay inequity in order to allow the data to contradict it if possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import wages data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: What are the priors and likelihood?\n",
    "We actually have _four_ variables to set priors on here. Most of them we actually don't have any relevant prior information for. We might set these as **noninformative priors** - that is, priors that are incredibly vague and provide no information:\n",
    "\n",
    "* $\\beta_0$ and $\\beta_1$ - noninformative, we have no prior information.\n",
    "* $\\sigma$ - the model's variance - also noninformative, we have no good guesses.\n",
    "* $\\beta_2$ - the coefficient of protected class. We'll put a prior that assumes $\\beta_2 \\approx 0$ in order to assume innocence.\n",
    "\n",
    "For the likelihood, remember our parametrization of OLS as a GLM:\n",
    "\n",
    "$$Y = \\mathbf{x}^T\\beta + \\varepsilon$$\n",
    "\n",
    "where $\\varepsilon \\sim N(0, \\sigma)$, and so\n",
    "\n",
    "$$ Y \\sim N(\\mathbf{x}^T\\beta, \\sigma) $$\n",
    "\n",
    "So we can write \n",
    "\n",
    "$$ \\log W \\sim N(\\beta_0 + \\beta_1\\text{skill} + \\beta_2\\text{class}, \\sigma) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Priors\n",
    "\n",
    "\n",
    "# Likelihoods\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: PyMC3 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyMC3 Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traceplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exponentiate beta_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected value for e^beta_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to `statsmodels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X = wages.loc[:, [\"skill\", \"class\"]]\n",
    "X = sm.add_constant(X)\n",
    "y = np.log(wages[\"wage\"])\n",
    "lm = sm.OLS(y,X).fit()\n",
    "lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This was actually simulated to be 0.8\n",
    "np.exp(-0.1853)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
